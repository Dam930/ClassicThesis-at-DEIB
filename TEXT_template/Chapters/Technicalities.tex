\chapter{State of the art}\label{chap:art}

\vspace{-0.05in}
In this section, we provide the essential background on policy gradient methods and stochastic variance-reduced gradient methods for finite-sum optimization.
\vspace{-0.05in}

\section{Policy Gradient}\label{sec:PolicyGradient}
\vspace{-0.05in}
A Reinforcement Learning task~\citep{sutton1998reinforcement} can be modelled with a discrete-time continuous Markov Decision Process (MDP) $M = \{\Sspace,\Aspace,\Transition,\Reward,\gamma,\rho\}$, where $\Sspace$ is a continuous state space; $\Aspace$ is a continuous action space; $\Transition$ is a Markovian transition model, where $\Transition(s'|s,a)$ defines the transition density from state $s$ to $s'$ under action $a$; $\Reward$ is the reward function, where $\Reward(s,a) \in [-R,R]$ is the expected reward for state-action pair $(s,a)$;
% and $R$ is the maximum absolute-value reward;
$\gamma\in[0,1)$ is the discount factor; and $\rho$ is the initial state distribution.
The agent's behaviour is modelled as a policy $\pi$, where $\pi(\cdot|s)$ is the density distribution over $\Aspace$ in state $s$.
% We consider episodic tasks, \ie tasks composed of episodes of length $H$, also called time horizon.
% In this setting, a trajectory $\tau$ is the sequence of states and actions $(s_0,a_0,s_1,a_1,\dots,s_{H-1},a_{H-1})$ observed by following some stationary policy in a given episode, where $s_0$ is always sampled from the initial state distribution $\rho$.
We consider episodic MDPs with effective horizon $H$.\footnote{The episode duration is a random variable, but the optimal policy can reach the target state (\ie absorbing state) in at most $H$ steps. This has not to be confused with a finite horizon problem where the optimal policy is non-stationary.} In this setting, we can limit our attention to trajectories of length $H$. A trajectory $\tau$ is a sequence of states and actions $(s_0,a_0,s_1,a_1,\dots,s_{H-1},a_{H-1})$ observed by following a stationary policy, where $s_0 \sim \rho$.
We denote with $p(\tau|\pi)$ the density distribution induced by policy $\pi$ on the set $\Tspace$ of all possible trajectories (see Appendix~\ref{A:gradient_estimators} for the definition), and with $\Reward(\tau)$ the total discounted reward provided by trajectory $\tau$:
%
$\Reward(\tau) = \sum_{t=0}^{H-1}\gamma^t\Reward(s_t,a_t).$
%
Policies can be ranked based on their expected total reward: $J(\pi) = \EVV[\tau \sim p(\cdot|\pi)]{\Reward(\tau)|M}$.
Solving an MDP $M$ means finding $\pi^* \in \argmax_{\pi} \{J(\pi)\}$.

Policy gradient methods restrict the search for the best performing policy over a class of parametrized policies $\Pi_{\vtheta}=\{\pol: \vtheta \in \realspace^d\}$, with the only constraint that $\pol$ is differentiable \wrt $\vtheta$. For sake of brevity, we will denote the performance of a parametric policy with $J(\vtheta)$ and the probability of a trajectory $\tau$ with $p(\tau|\vtheta)$ (in some occasions, $p(\tau|\vtheta)$ will be replaced by $p_{\vtheta}(\tau)$ for the sake of readability).
The search for a locally optimal policy is performed through gradient ascent, where the policy gradient
%of $J(\vtheta)$ \wrt the policy parameters 
is \cite{sutton2000policy, Peters2008reinf}:
\begin{align} \label{E:policygradient}
	\gradJ{\vtheta} = \EVV[\tau \sim p(\cdot|\vtheta)]{\score{\vtheta}{\tau}\Reward(\tau)}.
	%\int_{\Tspace}\pol(\tau)\score{\vtheta}{\tau}\Reward(\tau)\de \tau.
\end{align}
Notice that the distribution defining the gradient is induced by the current policy. This aspect introduces a nonstationarity in the sampling process. Since the underlying distribution changes over time, it is necessary to resample at each update or use weighting techniques such as importance sampling.
Here, we consider the \emph{online learning scenario}, where trajectories are sampled by interacting with the environment at each policy change. 
In this setting, stochastic gradient ascent is typically employed.
At each iteration $k >0$, a batch $\mathcal{D}_N^k = \{\tau_i\}_{i=0}^N$ of $N>0$ trajectories is collected using policy $\pi_{\vtheta_k}$.
The policy is then updated as $\vtheta_{k+1}  = \vtheta_k + \alpha\gradApp{\vtheta_k}{N}$, where $\alpha$ is a step size and $\gradApp{\vtheta}{N}$ is an estimate of Eq.~\eqref{E:policygradient} using $\mathcal{D}_N^k$. The most common policy gradient estimators (\eg REINFORCE~\citep{williams1992simple} and G(PO)MDP~\citep{baxter2001infinite}) can be expressed as follows
\begin{align} \label{E:policygradient.estimate}
	\gradApp{\vtheta}{N} = \frac{1}{N}\sum_{n=1}^{N} g(\tau_i|\vtheta), \quad \tau_i \in \mathcal{D}_N^k,
\end{align}
where $g(\tau_i|\vtheta)$ is an estimate of $\score{\vtheta}{\tau_i}\Reward(\tau_i)$.
Although the REINFORCE definition is simpler than the G(PO)MDP one, the latter is usually preferred due to its lower variance.
We refer the reader to Appendix~\ref{A:gradient_estimators} for details and a formal definition of $g$.

The main limitation of plain policy gradient is the high variance of these estimators.
The na\"ive approach of increasing the batch size is not an option in RL due to the high cost of collecting samples, \ie by interacting with the environment.
For this reason, literature has focused on the introduction of baselines (\ie functions $b : \mathcal{S} \times \mathcal{A} \to \realspace$) aiming to reduce the variance~\citep[\eg][]{williams1992simple,Peters2008reinf,Thomas2017actionbaseline,wu2018variance}, see Appendix~\ref{A:gradient_estimators} for a formal definition of $b$.
These baselines are usually designed to minimize the variance of the gradient estimate, but even them need to be estimated from data, partially reducing their effectiveness.
On the other hand, there has been a surge of recent interest in variance reduction techniques for gradient optimization in supervised learning (SL).
Although these techniques have been mainly derived for finite-sum problems, we will show in Section~\ref{sec:alg} how they can be used in RL.
In particular, we will show that the proposed SVRPG algorithm can take the best of both worlds (\ie SL and RL) since it can be plugged into a policy gradient estimate using baselines.
The next section has the aim to describe variance reduction techniques for finite-sum problems. In particular, we will present the SVRG algorithm that is at the core of this work.


\vspace{-0.05in}
\section{Install \LaTeX}
If you don't have already a \LaTeX\ system installed, this section will explain everything you need.
The easiest way to get \LaTeX\ is to install TeXLive, which works on all \acp{OS}.
In \url{https://www.tug.org/texlive/} you find the instructions and the files needed - and also get in touch with minimalism of \TeX users. 

Then you will need an editor: I strongly recommend TeXworks because it's very simple and available on all the platforms.
Also you don't need to install it, it's already included in TeXLive.
The official documentation of TeXworks is available \href{https://docs.google.com/file/d/0B5iVT8Q7W44pMk1WSFRKcDRlMU0/preview}{here};\footnote{\url{https://docs.google.com/file/d/0B5iVT8Q7W44pMk1WSFRKcDRlMU0/preview}}
I strongly recommend the reading of chapter 3.
Alternatevely you can read an italian manual: \href{http://profs.sci.univr.it/~gregorio/introtexworks.pdf}{profs.sci.univr.it/~gregorio/introtexworks.pdf} (just 13 pages, read it!).\footnote{If you already have a preferred editor, just keep using yours.}

After opening TeXworks, I strongly suggest to set these two additional things:
\begin{itemize}
	\item open Preferences, then go the Composition tab: in the second box there, the \enquote{Process instruments}, push the plus button.
	In the window just opened, write \verb!Biber! in the \enquote{Name} field, \verb!biber! in the \enquote{Program} field (lowercase!) and then press the plus button to add the argument \verb!$basename!;
	\item again in the same window, set \enquote{Hide console output} to \enquote{never}.
\end{itemize}

Then just test the installation of the template:
\begin{aenumerate}
	\item go into the template home folder;
	\item open the file \verb!ClassicThesis_DEIB.tex!;
	\item select \verb!pdfLaTeX! from the dropdown menu in the top right of the TeXworks window;
	\item press the rounded green button: it compiles the \verb!.tex! file for the first time and open the resulting \verb!.pdf!;
	\item select \verb!Biber! from the same dropdown menu and press again the green button: this compiles the bibliography, a thing you need to repeat only when you change the file \verb!Bibliography.bib!;
	\item select \verb!pdfLaTeX! again and recompile: this is needed to build indices and crossreferences;
\end{aenumerate}
The above compilation procedure is the standard way to translate the \LaTeX\ code into pdfs.

\subsection{Online editor}
If the above procedure seems too difficult to you and you have an internet connection always available, you might think to use an online editor.
The best choice at the time of writing is \url{http:\\\\sharelatex.com} where you can even find this template after registration to the site by looking for \enquote{Classic Thesis At DEIB}.
Your project will be saved on their server but you can also download them.
The platform allows up to two authors for free accounts.

There is no need to provide instructions for its use since the website has them.
They also have an online \LaTeX guide.

\section{Use \LaTeX\ within this template}

\subsection{File structure}
The template is organized in multiple file and folders:
\begin{aenumerate}

	\item \verb!ClassicThesis_DEIB.tex! is the main file to be compiled, found in the root folder.
	You should just add the source filenames you want to include and any hyphenation you need to explictly specify. 

	\item \verb!classicthesis-config.tex! contains options that can be chosen for this template, like the \verb!draft! one that prints date and time at the bottom of every page.
	It contains also the definition for the title, the author and others stuff displayed in the titlepage.
	Comments within the file should guide you.\footnote{comments are the rows starting with $\%$.} 
	Take a look at it!

	\item \verb!Bibliography.bib! is the \emph{Bibtex} database: it is a normal textfile where you should put books and articles read;

	\item \verb!Chapters! contains the files for the main chapters of your thesis; this is where you will add the chapters text, as well these very words in line 41 of the file \verb!Conclusion.tex!;

	\item \verb!CodeFiles! contains any code snippet you want to include in your thesis with the environment \verb!listings!; it might be some relevant Matlab or C code, as well as long bash scripts;

	\item \verb!FrontBackmatter! contains various files that are included in the main one to produce abstract, titlepages, acknowledgements, \ldots. 
	Follow the instructions below to modify them in order to suits your needs;

	\item \verb!Images! contains the \verb!.pdf! or \verb!.png! versions of the images of the thesis organized in subfolder per chapter.

\end{aenumerate}

To modify abstract, preface, acknowledgements snd acronyms, you need to go into the folder \verb!FrontBackmatter! where you will find the following:
\begin{description}

	\item[Abstract.tex] contains the text displayed as \enquote{abstract} and \enquote{sommario} just after the list of figures, tables, etc. Modify the text and leave the rest.

	\item[Acknowledgments.tex] contains the text put just before the table of contents. Modify the text to suit your needs.

	\item[Acronyms.tex] contains the environment \verb!acronym! with the definition of all the acronyms that will be used within the text. Add your own to the list and put the longest as parameter of the environment.
 
	\item[AutoParts] folder contains things that should work without your intervention. Forget them. 

	\item[Dedication.tex] same usage and structure as \verb!Acknowledgements.tex!.

	\item[Estratto.tex] Politecnico di Milano requires an italian long excerpt of theses written in foreign languages.

	\item[Frontespizio.tex] and \verb!FrontespizioIT.tex! are the cover page in english and italian, respectively. Politecnico di Milano requires the italian version of the english cover, so there it is. Both should work perfectly if you modify section 2 of the file \verb!classicthesis-config.tex!, but you may not like the style so modify them as you prefer.
	
	\item[Preface.tex] same usage and structure as \verb!Acknowledgements.tex!.

	\item[Publication.tex] same usage and structure as \verb!Acknowledgements.tex!, but not included by default. Activate it by uncommenting the relevant line in \verb!ClassicThesis_DEIB.tex!.

	\item[RetroFrontespizio.tex] contains the colophon. In most cases is fine as it already is.
\end{description}

\subsection{Special environments}\label{subsec:special_env}
In addition to common \LaTeX\ environments, this thesis is set to use:
\graffito{Use these environments: they make the thesis less bland and readable.}
\begin{itemize}
	\item the command \verb!\graffito{}! is used to create margin notes.
	The limits in number of words or length of word must be seen as a motivation to keep the notes short and simple;
	\item \verb!\begin{aenumerate}! to produce an \verb!\enumerate! with letters instead of numbers, as in the file list above;
	\item footnotes are useful to provide extra information. 
	Usually they are not required to understand a paragraph but provide interesting details. 
	This keeps the main body of text concise.
	You can create them with \verb!\footnote{text}!.\footnote{They should be placed after the punctuation mark and preferably at the end of the paragraph. In fact, they should not interrupt the reading flow. If you need to put a footnote in the middle of a paragraph, or of a sentence then the note should be part of the main text.}
	\item \verb!\ac{}! and its variations, defined by package \verb!acronyms!, provide nice handling for acronyms, like \ac{XML}, produced with the code \verb!\ac{XML}!.
	List them within the environment \verb!acronym! in the file \verb!FrontBackmatter/Acronyms.tex!.
\end{itemize}

\subsection{Citing, quoting and referencing}
References to bibliography are produced in the usual way with \verb!\cite{bib_key}! (\cite{bringhurst:2002}); don't forget the brackets which have to be added by hand.
There also variations of the command, like \verb!\citeauthor{bib_key}!, \verb!\citetitle{bib_key}! and others that you can find in the \verb!bibtex! manual.

\verb!\blockcquote[][]{}{}! \blockcquote[see][p. 111]{bringhurst:2002}{produce a quotation with reference to author and page}.
If the quotation is longer than two rows is indented.
This behavior is provided by the package \verb!csquotes!, which settings are in \verb!classicthesis-config.tex!. 
The package also provides \verb!\enquote{!the citation\verb!}! that produces \enquote{correct quotation style} according to the language in use.

There is a set of commands to refer to chapters, sections, subsections, appendices, figures, tables and equations, like \verb!\myChap{label_key}! to produce \myChap{chap:aChapter}.
There are also capital versions of the commands (\verb!\MyChap{}! produces \MyChap{chap:aChapter}).
They need a \verb!\label{name}! anchor next to the referred thing.
\begin{itemize}
	\item\verb!\myChap! for chapters;
	\item\verb!\mySec! for sections;
	\item\verb!\mySubsec! for subsections;
	\item\verb!\myAppendix! for appendices;
	\item\verb!\myFig! for figures;
	\item\verb!\myTab! for tables;
	\item\verb!\myEq! for equations;
\end{itemize}

\subsection{Figures and tables}
Figures are handled usually with the code
\begin{verbatim}
	\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{Images/your_image_name.pdf} 
	\caption[Short description]{Long description.}
	\label{fig:a_name}
	\end{figure}
\end{verbatim}
which produces things like \myFig{fig:massConstraintFeasibility}. 
Take care of the short description: it appears in the list of figures and should be just a reference, not a exhaustive description.
Of course, you need to put the image file \verb!your_image_name.pdf! in folder \verb!Images/!.
We suggest to keep things organized: create a folder for each chapter and keep the original source/working file in the same place.
	
\begin{figure}
\centering
\includegraphics[width=\columnwidth]{Images/Technicalities/feasibilityNR51.pdf}  
\caption[Thing taken from our master thesis]{Thing taken from our master thesis whose meaning have been completely forgotten.}
\label{fig:massConstraintFeasibility}
\end{figure}

\begin{table}
\footnotesize
\centering
\begin{tabularx}{0.8\textwidth}{llrcl}
\toprule
\tableheadline{l}{Algorithm} &
\tableheadline{l}{Parameter} &
\tableheadlineMore{3}{c}{Suggested Values} \\
\midrule
\tablefirstcol{l}{Any}	& NFE	 		& $10\,000 $ 	& $ \div $ 	& $ 200\,000$ \\
				& Population Size 	&  $10 $ 		& $ \div $ 	& $ 1000$ \\
\midrule
\tablefirstcol{l}{GDE3} & DE step size 		& $0.0 $ 	& $\div $ 	& $ 1.0$ \\
				& Crossover rate 	& $0.0$ 	& $ \div $ 	& $ 1.0$ \\
\bottomrule
\end{tabularx}
\caption[Parameters needed for things]{Parameters needed for things that are not needed anymore themselves.}
\label{tab:MOEAandParameters}
\end{table}

Tables are produced with the code
\begin{verbatim}
	\begin{table}[tb]
	\footnotesize
	\centering
	\begin{tabularx}{0.8\textwidth}{llrcl}
	\toprule
	\tableheadline{l}{Algorithm} &
	\tableheadline{l}{Parameter} &
	\tableheadlineMore{3}{c}{Suggested Values} \\
	\midrule
	\tablefirstcol{l}{Any}
	& \acs{NFE} 		& $10\,000 $ & $ \div $ & $ 200\,000$ \\
	& Population Size 	&  $10 $ & $ \div 	$ & $ 1000$ \\
	\midrule
	\tablefirstcol{l}{\ac{GDE3}}
	& \ac{DE} step size & $0.0 $ & $\div $ & $ 1.0$ \\
	& Crossover rate 	& $0.0$ & $ \div $ & $ 1.0$ \\
	\bottomrule
	\end{tabularx}
	\caption[Short description]{Long description.}
	\label{tab:MOEAandParameters}
	\end{table}
\end{verbatim}
which produces \myTab{tab:MOEAandParameters}.
\verb!\myfloatalign!, \verb!\tableheadline{}{}! and its variation \verb!\tableheadlineMore{}{}{}! and \verb!\tablefirstcol{}{}! are used to give a common style to all tables in the document.
Use them!
They are defined in \verb!classicthesis-config.tex!.

\subsection{Math}
You can produce an equation like $\lim_{n \to \infty}\sum_{k=1}^n \frac{1}{k^2}= \frac{\pi^2}{6}$ by embedding this code in the line:
\begin{verbatim}
	$\lim_{n \to \infty}\sum_{k=1}^n \frac{1}{k^2}= \frac{\pi^2}{6}$.
\end{verbatim}

Equation that spans the full line like:
\[
\lim_{n \to \infty}\sum_{k=1}^n \frac{1}{k^2}= \frac{\pi^2}{6}
\]
are produced with something like this:
\begin{verbatim}
	\[
	\lim_{n \to \infty}\sum_{k=1}^n \frac{1}{k^2}= \frac{\pi^2}{6}.
	\]
\end{verbatim}
If you need to refer to the equation later on, you need to number and label it. It is done via
\begin{verbatim}
	\begin{equation}
	\label{eq:euler}
	e^{i\pi}+1=0.
	\end{equation}
\end{verbatim}
\begin{equation}
	\label{eq:euler}
	e^{i\pi}+1=0.
\end{equation}
From \myEq{eq:euler} you can see how \verb!\myEq{eq:euler}! should be used.

Numeric sets requires specific font as $\forall x \in \mathbb{R}$ which is produced with \verb!$\forall x \in \mathbb{R}$!. Matrices like
\[
A=
\begin{bmatrix}
x_{11} & x_{12} & \dots \\
x_{21} & x_{22} & \dots \\
\vdots & \vdots & \ddots
\end{bmatrix}
\]
requires
\begin{verbatim}
	A=
	\begin{bmatrix}
		x_{11} & x_{12} & \dots \\
		x_{21} & x_{22} & \dots \\
		\vdots & \vdots & \ddots
	\end{bmatrix}.
\end{verbatim}
Multiline equation can be produced with different environments like \verb!split! and \verb!cases!.
\[ 
\begin{split} 
a &= b+c-d \\ 
  &= e-f \\ 
  &= g+h \\ 
  &= i. 
\end{split} 
\]
comes from
\begin{verbatim}
	\begin{split} 
	a &= b+c-d \\ 
 	&= e-f \\ 
	&= g+h \\ 
	&= i. 
	\end{split}. 
\end{verbatim}
\[
f(n):=
\begin{cases} 
2n+1, & \text{con $n$ dispari,} \\ 
n/2,  & \text{con $n$ pari.} 
\end{cases} 
\]
comes from
\begin{verbatim}
	\begin{split} 
	a &= b+c-d \\ 
 	&= e-f \\ 
	&= g+h \\ 
	&= i. 
	\end{split}. 
\end{verbatim}

Definition like
\begin{definition}[Gauss] 
The math guy find obvious that
$\int_{-\infty}^{+\infty}
e^{-x^2}\,dx=\sqrt{\pi}$. 
\end{definition}
are produced with the code 
\begin{verbatim}
\begin{definition}[Gauss] 
The math guy find obvious that
$\int_{-\infty}^{+\infty}
e^{-x^2}\,dx=\sqrt{\pi}$. 
\end{definition}
\end{verbatim}
There also a number of other similar environments, like \verb!observation!, \verb!theorem! with or without name, \verb!corollary! and \verb!lemma!.
\begin{observation}
But many people like me don't find it obvious.
\end{observation}
\begin{theorem} 
Mathematicians are very rare, if any.
\end{theorem} 
\begin{theorem}[Pythagorean]
The square of the hypotenuse of a triangle is equal to the sum of the squares of the other two sides.
\end{theorem}
Demonstration is left for exercise.
\begin{corollary}
A line segment whose length is incommensurable so the ratio of which is not a rational number, can be constructed using a straightedge and compass. 
\end{corollary}
\begin{lemma}
Pythagoras's theorem enables construction of incommensurable lengths because the hypotenuse of a triangle is related to the sides by the square root operation.
\end{lemma}
You can also proof your theorem with the environment \verb!proof!.
\begin{theorem}[Surprise]
We have $\log(-1)^2=2\log(-1)$.
\end{theorem} 
\begin{proof} 
We have $\log(1)^2 = 2\log(1)$.
But also we have $\log(-1)^2=\log(1)=0$.
So $2\log(-1)=0$.
\end{proof}
There's also the cute little square at the end.

\section{Contributing to this template}
Suggestion and improvements are welcome at \url{https://github.com/Lordmzn/ClassicThesis-at-DEIB} or via email at \url{emanuele.mason@polimi.it}, \url{andrea.cominola@polimi.it} or \url{daniela.anghileri@polimi.it}.